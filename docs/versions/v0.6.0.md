# v0.6.0: Rubric Grading

**Status:** Planned

## Overview

LLM-powered qualitative evaluation for goals that can't be checked deterministically.

## Features

- Define rubrics in YAML
- LLM-as-judge evaluation
- Structured scoring output

## CLI Commands

```bash
sklab eval-rubric ./my-skill --artifacts ./output/
```

## Rubric Definition

```yaml
# tests/rubric.yaml
rubric:
  - criterion: code_quality
    weight: 0.3
    description: "Code follows best practices"

  - criterion: documentation
    weight: 0.2
    description: "README and comments are clear"

  - criterion: error_handling
    weight: 0.25
    description: "Errors handled gracefully"

  - criterion: conventions
    weight: 0.25
    description: "Output matches expected structure"
```

## Architecture

```
src/skill_lab/
├── rubrics/
│   ├── models.py              # Rubric, RubricCriterion, RubricResult
│   ├── loader.py              # YAML loader
│   └── evaluator.py           # LLM-as-judge evaluation
└── llm/
    ├── provider.py            # LLM provider abstraction
    ├── openai_provider.py     # OpenAI implementation
    └── anthropic_provider.py  # Anthropic implementation
```

## Deliverables

- [ ] Rubric, RubricCriterion, RubricResult models
- [ ] LLM provider abstraction (OpenAI + Anthropic)
- [ ] Rubric YAML loader
- [ ] RubricEvaluator with structured output
- [ ] CLI command: `sklab eval-rubric`
